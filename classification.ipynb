{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alysson = pd.read_csv('MARCADOS_CONSISTENCIA/Alysson.csv', sep=';', encoding='utf-8')\n",
    "alysson.columns = ['id', 'tweet', 'candidato', 'marcador', 'classe']\n",
    "alysson = alysson[alysson.marcador == 'alysson']\n",
    "alysson = alysson.drop_duplicates()\n",
    "\n",
    "raul = pd.read_csv('MARCADOS_CONSISTENCIA/Raul.csv', sep=';', encoding='utf-8')\n",
    "raul.columns = ['id', 'tweet', 'candidato', 'marcador', 'classe']\n",
    "raul = raul[raul.marcador == 'raul']\n",
    "raul = raul.drop_duplicates()\n",
    "\n",
    "dalai = pd.read_csv('MARCADOS_CONSISTENCIA/Dalai.csv', sep=';', encoding='utf-8')\n",
    "dalai.columns = ['id', 'tweet', 'candidato', 'marcador', 'classe']\n",
    "dalai = dalai[dalai.marcador == 'dalai']\n",
    "dalai = dalai.drop_duplicates()\n",
    "\n",
    "romulo = pd.read_csv('MARCADOS_CONSISTENCIA/Romulo.csv', sep=';', encoding='utf-8')\n",
    "romulo.columns = ['id', 'tweet', 'candidato', 'marcador', 'classe']\n",
    "romulo = romulo[romulo.marcador == 'romulo']\n",
    "romulo = romulo.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([alysson,raul,dalai, romulo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1412, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[data['classe'] != 'N√£o sei']\n",
    "data['classe'][data['classe'] == 'Rejei√ß√£o'] = 'REJEICAO'\n",
    "data['classe'][data['classe'] == 'Neutro'] = 'NEUTRO'\n",
    "data['classe'][data['classe'] == 'Aprova√ß√£o'] = 'APROVACAO'\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1151, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessing(twitterText):\n",
    "    #Remover \\n\n",
    "    twitterText = re.sub(\"\\n+\",\" \",twitterText)\n",
    "\n",
    "    #Remover multiplos espa√ßos\n",
    "    twitterText = re.sub(\" +\",\" \",twitterText)\n",
    "    \n",
    "    #(@usu√°rio) pelo termo ‚ÄôAT_USER‚Äô tal como sugerido em [Almatrafi et al., 2015].\n",
    "    twitterText = re.sub(\"@\\w+\",\"atuser\",twitterText)\n",
    "\n",
    "    #Remove links\n",
    "    twitterText = re.sub(r\"http\\S+\", \"\",twitterText)\n",
    "\n",
    "    #Remover caracteres especiais\n",
    "    twitterText = re.sub(\"[@|#|‚Äú|‚Äù|‚Äô|‚Äò|¬Æ|,|!|?||\\[|\\]|\\.|\\\"|%|:|\\-|_|/|¬™|\\(|\\)|¬∞|\\*|üáß|üá∑|\\'|Ô∏è|=]\",'',twitterText)\n",
    "\n",
    "    #Remover n√∫meros\n",
    "    twitterText = re.sub(\"[0-9]+\",'',twitterText)\n",
    "\n",
    "    #Tokenize\n",
    "    twitterTokens = TweetTokenizer().tokenize(twitterText)\n",
    "\n",
    "    #transforme emojis em textcode\n",
    "    twitterTokensEmojisCode = []\n",
    "    for token in twitterTokens:\n",
    "        if(token in UNICODE_EMOJI):\n",
    "            twitterTokensEmojisCode.append(UNICODE_EMOJI[token])\n",
    "        else:\n",
    "            twitterTokensEmojisCode.append(token)\n",
    "    twitterTokens = twitterTokensEmojisCode\n",
    "\n",
    "    #remove stopwords\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    stopwords.remove(\"n√£o\")\n",
    "    stopwords.remove(\"num\")\n",
    "    twitterTokens = [token for token in twitterTokens if (token not in stopwords) ]\n",
    "    \n",
    "    #Lower case\n",
    "    twitterText = \"\".join(twitterText)\n",
    "    twitterText = twitterText.lower()\n",
    "\n",
    "    return twitterText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['tweet'] = data['tweet'].apply(lambda x : preProcessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>candidato</th>\n",
       "      <th>marcador</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>twe984802485360582656</td>\n",
       "      <td>ao inv√©s dos petistas estarem buscando livrar ...</td>\n",
       "      <td>alckmin</td>\n",
       "      <td>alysson</td>\n",
       "      <td>REJEICAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twe977572021361168389</td>\n",
       "      <td>atuser atuser atuser atuser o problema caio √© ...</td>\n",
       "      <td>manuela</td>\n",
       "      <td>alysson</td>\n",
       "      <td>NEUTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>twe977558211447443457</td>\n",
       "      <td>a pergunta √© s√©ria atuser quer me pagar logo o...</td>\n",
       "      <td>manuela</td>\n",
       "      <td>alysson</td>\n",
       "      <td>REJEICAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>twe977347407011897345</td>\n",
       "      <td>disparado</td>\n",
       "      <td>bolsonaro</td>\n",
       "      <td>alysson</td>\n",
       "      <td>NEUTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>twe984494027956543488</td>\n",
       "      <td>o que acontece agora que o inqu√©rito de alckmi...</td>\n",
       "      <td>alckmin</td>\n",
       "      <td>alysson</td>\n",
       "      <td>NEUTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>twe981677295676084224</td>\n",
       "      <td>a√©cio √© flagrado pedindo grana a empres√°rio  ...</td>\n",
       "      <td>temer</td>\n",
       "      <td>alysson</td>\n",
       "      <td>REJEICAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>twe978200570740822017</td>\n",
       "      <td>se a bunda de algum ministro sentar sobre o pr...</td>\n",
       "      <td>lula</td>\n",
       "      <td>alysson</td>\n",
       "      <td>REJEICAO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>twe982682347484180482</td>\n",
       "      <td>hoje n√£o h√° lado certo ou lado errado lula √© f...</td>\n",
       "      <td>temer</td>\n",
       "      <td>alysson</td>\n",
       "      <td>NEUTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>twe984980191066849280</td>\n",
       "      <td>decis√µes do stf e do stj de encaminhar process...</td>\n",
       "      <td>alckmin</td>\n",
       "      <td>alysson</td>\n",
       "      <td>NEUTRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>twe983555366133944320</td>\n",
       "      <td>para os que ainda n√£o sabem a pr√©candidata √† p...</td>\n",
       "      <td>marina</td>\n",
       "      <td>alysson</td>\n",
       "      <td>NEUTRO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                              tweet  \\\n",
       "2   twe984802485360582656  ao inv√©s dos petistas estarem buscando livrar ...   \n",
       "3   twe977572021361168389  atuser atuser atuser atuser o problema caio √© ...   \n",
       "4   twe977558211447443457  a pergunta √© s√©ria atuser quer me pagar logo o...   \n",
       "5   twe977347407011897345                                        disparado     \n",
       "6   twe984494027956543488  o que acontece agora que o inqu√©rito de alckmi...   \n",
       "7   twe981677295676084224   a√©cio √© flagrado pedindo grana a empres√°rio  ...   \n",
       "8   twe978200570740822017  se a bunda de algum ministro sentar sobre o pr...   \n",
       "9   twe982682347484180482  hoje n√£o h√° lado certo ou lado errado lula √© f...   \n",
       "10  twe984980191066849280  decis√µes do stf e do stj de encaminhar process...   \n",
       "11  twe983555366133944320  para os que ainda n√£o sabem a pr√©candidata √† p...   \n",
       "\n",
       "    candidato marcador    classe  \n",
       "2     alckmin  alysson  REJEICAO  \n",
       "3     manuela  alysson    NEUTRO  \n",
       "4     manuela  alysson  REJEICAO  \n",
       "5   bolsonaro  alysson    NEUTRO  \n",
       "6     alckmin  alysson    NEUTRO  \n",
       "7       temer  alysson  REJEICAO  \n",
       "8        lula  alysson  REJEICAO  \n",
       "9       temer  alysson    NEUTRO  \n",
       "10    alckmin  alysson    NEUTRO  \n",
       "11     marina  alysson    NEUTRO  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bag of words\n",
    "def featureextractionBOW(X):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    #Redu√ß√£o de dimensionalidade Truncated SVD (PCA para matrizes espa√ßas)\n",
    "    svd = TruncatedSVD(n_components=300)\n",
    "    X_truncated = svd.fit_transform(X)\n",
    "    return X_truncated\n",
    "\n",
    "#TFIDF\n",
    "def featureextractionTFIDF(X):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(X)\n",
    "    tfidf = TfidfTransformer()\n",
    "    X = tfidf.fit_transform(X)\n",
    "    #Redu√ß√£o de dimensionalidade Truncated SVD (PCA para matrizes espa√ßas)\n",
    "    svd = TruncatedSVD(n_components=300)\n",
    "    X_truncated = svd.fit_transform(X)\n",
    "    return X_truncated\n",
    "\n",
    "class FeatureGeneratorMedia:\n",
    "    def __init__(self, X, w2vmodel, num_features):\n",
    "        self.X = X\n",
    "        self.w2vmodel = w2vmodel\n",
    "        self.num_features = num_features\n",
    "        self.features_vec = None\n",
    "\n",
    "    def gen_features_dataset(self):\n",
    "        self.X = self.X.apply(lambda text: TweetTokenizer().tokenize(text) )\n",
    "        X_array = []\n",
    "        self.X.apply(lambda listText: X_array.append(self.make_features_vec(listText)) )\n",
    "        \n",
    "        return np.matrix(X_array)\n",
    "        \n",
    "    def make_features_vec(self, tweet):\n",
    "        featureVec = np.zeros(self.num_features)\n",
    "        nwords = 0.0\n",
    "        index2word_set = set(self.w2vmodel.wv.index2word)\n",
    "        for word in tweet:\n",
    "            if word in index2word_set:\n",
    "                featureVec = np.add(featureVec, self.w2vmodel[word])\n",
    "                nwords += 1\n",
    "        if nwords == 0.0:\n",
    "            nwords = 1.0\n",
    "        return np.divide(featureVec, nwords)\n",
    "\n",
    "def featureextractionWord2VecMean(X):\n",
    "    num_features=300\n",
    "    model = word2vec.Word2Vec.load(\"/home/alysson/Documents/Tweets/word2vec_files/tweets_presidential_elections_300_min1_cont2_cbow\")\n",
    "    featureGeneratorMedia = FeatureGeneratorMedia(X,model,num_features)\n",
    "    return featureGeneratorMedia.gen_features_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data['tweet']\n",
    "Y = data['classe']\n",
    "\n",
    "featureExtractionList = [(\"BOW\",featureextractionBOW),(\"TFIDF\",featureextractionTFIDF),(\"W2Vmean\",featureextractionWord2VecMean)]\n",
    "\n",
    "modelsName = ['XGBoost', 'GradientBoosting', 'kNN']\n",
    "listModels = [XGBClassifier(),GradientBoostingClassifier(),KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration # 1: BOW+XGBoost\n",
      "inicio treino\n",
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.47      0.18      0.26        51\n",
      "     NEUTRO       0.50      0.41      0.45        78\n",
      "   REJEICAO       0.73      0.88      0.80       217\n",
      "\n",
      "avg / total       0.64      0.67      0.64       346\n",
      "\n",
      "Time:  6.867495059967041\n",
      "\n",
      "\n",
      "Configuration # 1: BOW+GradientBoosting\n",
      "inicio treino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alysson/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.42      0.20      0.27        51\n",
      "     NEUTRO       0.48      0.41      0.44        78\n",
      "   REJEICAO       0.73      0.86      0.79       217\n",
      "\n",
      "avg / total       0.63      0.66      0.64       346\n",
      "\n",
      "Time:  11.093000411987305\n",
      "\n",
      "\n",
      "Configuration # 1: BOW+kNN\n",
      "inicio treino\n",
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.15      0.31      0.20        51\n",
      "     NEUTRO       0.32      0.40      0.35        78\n",
      "   REJEICAO       0.71      0.47      0.56       217\n",
      "\n",
      "avg / total       0.54      0.43      0.46       346\n",
      "\n",
      "Time:  0.22736024856567383\n",
      "\n",
      "\n",
      "Configuration # 1: TFIDF+XGBoost\n",
      "inicio treino\n",
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.42      0.10      0.16        51\n",
      "     NEUTRO       0.53      0.36      0.43        78\n",
      "   REJEICAO       0.71      0.92      0.80       217\n",
      "\n",
      "avg / total       0.63      0.67      0.62       346\n",
      "\n",
      "Time:  7.768298149108887\n",
      "\n",
      "\n",
      "Configuration # 1: TFIDF+GradientBoosting\n",
      "inicio treino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alysson/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.32      0.12      0.17        51\n",
      "     NEUTRO       0.48      0.31      0.38        78\n",
      "   REJEICAO       0.70      0.90      0.79       217\n",
      "\n",
      "avg / total       0.60      0.65      0.60       346\n",
      "\n",
      "Time:  10.239217519760132\n",
      "\n",
      "\n",
      "Configuration # 1: TFIDF+kNN\n",
      "inicio treino\n",
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.23      0.33      0.27        51\n",
      "     NEUTRO       0.28      0.78      0.41        78\n",
      "   REJEICAO       0.94      0.22      0.35       217\n",
      "\n",
      "avg / total       0.69      0.36      0.35       346\n",
      "\n",
      "Time:  0.15668010711669922\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alysson/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration # 1: W2Vmean+XGBoost\n",
      "inicio treino\n",
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.32      0.12      0.17        51\n",
      "     NEUTRO       0.50      0.50      0.50        78\n",
      "   REJEICAO       0.75      0.86      0.80       217\n",
      "\n",
      "avg / total       0.63      0.67      0.64       346\n",
      "\n",
      "Time:  7.59485387802124\n",
      "\n",
      "\n",
      "Configuration # 1: W2Vmean+GradientBoosting\n",
      "inicio treino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alysson/miniconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.31      0.18      0.23        51\n",
      "     NEUTRO       0.55      0.54      0.54        78\n",
      "   REJEICAO       0.76      0.84      0.80       217\n",
      "\n",
      "avg / total       0.64      0.67      0.65       346\n",
      "\n",
      "Time:  7.96818470954895\n",
      "\n",
      "\n",
      "Configuration # 1: W2Vmean+kNN\n",
      "inicio treino\n",
      "fim treino\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  APROVACAO       0.28      0.25      0.27        51\n",
      "     NEUTRO       0.51      0.38      0.44        78\n",
      "   REJEICAO       0.74      0.82      0.78       217\n",
      "\n",
      "avg / total       0.62      0.64      0.63       346\n",
      "\n",
      "Time:  0.14643406867980957\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "it = 1\n",
    "for extractionName,funcFeatureExtraction in featureExtractionList:\n",
    "    X_features = funcFeatureExtraction(X)\n",
    "    \n",
    "    # train test split (sempre mesmo split)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_features, Y, test_size=0.3, random_state=1)\n",
    "    \n",
    "    for nameModel,model in zip(modelsName,listModels):\n",
    "        configuration = extractionName+\"+\"+nameModel\n",
    "        print(\"Configuration # \"+str(it)+\": \"+configuration)\n",
    "        \n",
    "        start_time =  time.time()\n",
    "        #Treina modelo\n",
    "        print(\"inicio treino\")\n",
    "        model.fit(X_train,Y_train)\n",
    "        print(\"fim treino\")\n",
    "        #Submeter-se dados de treino ao modelo - Teste\n",
    "        Y_pred = model.predict(X_test)\n",
    "        #Avalia modelo\n",
    "        metricsStr = classification_report(Y_test,Y_pred)\n",
    "        print(metricsStr)\n",
    "        #print(precision_recall_fscore_support(Y_test,Y_pred))\n",
    "        timeexec = (time.time() - start_time)\n",
    "        print(\"Time: \",timeexec)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
